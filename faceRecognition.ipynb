{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac7cda17-dd86-4f45-affa-3da9217371e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: dlib in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (19.24.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python dlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af6fe37a-1ba0-4760-a656-a39724789b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bed3f94-b961-4799-87fc-56d2e95e2605",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c928145-dfb0-4c31-b253-2bba8a00a4a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_path = r\"C:\\Users\\ibrah\\faceDedectionAssistant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4d2f508-84a2-4caf-88ec-149184afd79b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = [] ## for the load images\n",
    "\n",
    "\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        image_path = os.path.join(dataset_path, filename)\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is not None:\n",
    "            images.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108f809f-7b9e-445e-891d-222cc267c663",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Lib-Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cc6616a-3709-408a-a7ab-155bc4261b1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e6d1ea5-9291-4abd-a9ff-22524e5f4737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for img in images:\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray_img)\n",
    "    \n",
    "    for face in faces:\n",
    "        x1, y1, x2, y2 = (face.left(), face.top(), face.right(), face.bottom())\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc7e10d-673f-465b-8c24-718ab9725807",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Getting Face Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "297e94b0-043b-4ef2-9b72-25885f3b7127",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "face_descriptor_extractor = dlib.face_recognition_model_v1('dlib_face_recognition_resnet_model_v1.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d94d0551-4335-47e7-bd1a-21a866a0c79d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "face_encodings = [] ## to save face features\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "for img in images:\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray_img)\n",
    "    \n",
    "    for face in faces:\n",
    "    \n",
    "        shape = predictor(gray_img, face)\n",
    "        face_encoding = face_descriptor_extractor.compute_face_descriptor(img,shape)\n",
    "        face_encodings.append(face_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5a6191-d034-4bf7-9565-05f2abbb8d4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Face Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c531c76a-f3b5-4dad-a948-fe67e64877f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".cache\n",
      ".ipynb_checkpoints\n",
      "coco.names\n",
      "dlib_face_recognition_resnet_model_v1.dat\n",
      "emma01.jpg\n",
      "emma02.jpg\n",
      "emma03.jpg\n",
      "faceRecognition.ipynb\n",
      "ibrahim01.jpg\n",
      "ibrahim02.jpg\n",
      "ibrahim03.jpg\n",
      "shape_predictor_68_face_landmarks.dat\n",
      "yolov4.cfg\n",
      "yolov4.weights\n"
     ]
    }
   ],
   "source": [
    "## let check the files so i can check the image index. Do not forget we only get jpeg or png format\n",
    "for filename in os.listdir(dataset_path):\n",
    "    print(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "175c83a3-849f-4731-9b7e-cc158f0e8527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "known_faces_encodings = []\n",
    "known_faces_names = []\n",
    "\n",
    "## Adding of Users face features\n",
    "\n",
    "### User1's faces\n",
    "\n",
    "known_faces_encodings.append(face_encodings[0])\n",
    "known_faces_names.append('name')\n",
    "\n",
    "known_faces_encodings.append(face_encodings[1])\n",
    "known_faces_names.append('name')\n",
    "\n",
    "### User2's faces\n",
    "\n",
    "known_faces_encodings.append(face_encodings[3])\n",
    "known_faces_names.append('name')\n",
    "\n",
    "known_faces_encodings.append(face_encodings[4])\n",
    "known_faces_names.append('name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f23eb4-484e-4173-a442-8abe62f1c397",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing with New picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c1133da-0348-4fb4-8ffa-d06f7b1ec756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# face_descriptor_extractor = dlib.face_recognition_model_v1('dlib_face_recognition_resnet_model_v1.dat')\n",
    "# ## testing\n",
    "# test_img = cv2.imread('') ### tanim yapmak istedigimiz yeni goruntu\n",
    "\n",
    "# ## making gray the image\n",
    "\n",
    "# gray_test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "# test_faces = detector(gray_test_img)\n",
    "\n",
    "# ## test yuzunun'de ozelliklerini cikar\n",
    "\n",
    "# for face in test_faces:\n",
    "#     shape = predictor(gray_test_img, face)\n",
    "#     face_encoding = face_descriptor_extractor.compute_face_descriptor(test_img,shape)\n",
    "    \n",
    "# ## test yuz ozelliklerini ilk yukledigimiz resim ile karsilastiralim\n",
    "\n",
    "#     distances = []\n",
    "\n",
    "#     for known_faces_encoding in known_faces_encodings:\n",
    "    \n",
    "#         distance = np.linalg.norm(np.array(face_encoding) - np.array(known_faces_encoding))\n",
    "    \n",
    "#         distances.append(distance)\n",
    "    \n",
    "#     min_distance_index = np.argmin(distances) ##np.argmin(distances), bu listedeki en küçük değerin olduğu yeri, yani indeksi bulu\n",
    "#     threshold = 0.6\n",
    "    \n",
    "#     if distances[min_distance_index] < threshold:\n",
    "#         name = known_faces_names[min_distance_index]\n",
    "#         print('Tespit edilen kisi: ', name)\n",
    "#     else:\n",
    "        \n",
    "#         print('Kisi tespit edilemedi')\n",
    "        \n",
    "#     ## Yuzun etrafina dikdortgen cizin\n",
    "#     x1, y1, x2, y2 = (face.left(), face.top(), face.right(), face.bottom())\n",
    "#     cv2.rectangle(test_img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "#     cv2.putText(test_img, name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    \n",
    "# cv2.imshow(\"Yüz Tanıma Sonucu\", test_img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8e680d-e334-4934-9a7f-57d494f9cba2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# API Integration - Time Info- Speak Command - YOLO- Face Detection Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f578360a-0f5d-4dc2-b3ff-95d4cabf908c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Web Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20308661-c738-4af0-966b-a93a8d3768d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7160a094-3d58-42f5-959b-1298c31150ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def open_spotify_homepage():\n",
    "#     urls = [\"https://gazeteoksijen.com/\",\n",
    "#             \"https://www.fanatik.com.tr/\"]\n",
    "            \n",
    "#     for url in urls:\n",
    "#         webbrowser.open(url)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9257f8bc-0f99-4082-a4a8-3f02a3cfe1ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The Weather API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bc4ce0c-8c8c-4ae2-bb29-96cd35b7c5a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c60e2f0-7a49-47d9-8a87-79121d3d1ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66245700-80e8-4f61-abbe-7f6ce323c38c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_weather_info(api_key, city):\n",
    "    \n",
    "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}&units=metric\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        weather = data['weather'][0]['description']\n",
    "        temperature = data['main']['temp']\n",
    "        return f'The weather in {city} is currently {weather} with a temperature of {temperature}°C.'\n",
    "    else:\n",
    "        return \"Could not retrieve weather information \" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a13fc7-3e5a-4940-891d-80e837cca40e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### News API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a17db0e-f27a-4f4c-aaae-5ad71dcd0007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_news(news_api):\n",
    "    \n",
    "    url = f\"https://newsapi.org/v2/top-headlines?sources=bbc-news&pageSize=10&apiKey={news_api}&language=en\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        articles = response.json().get('articles', []) ## if json does not exist return []\n",
    "        headlines = [article['title']for article in articles]\n",
    "        return headlines\n",
    "        \n",
    "    else: \n",
    "        return []\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb88715-f161-49ba-a2ec-38612561b4d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Getting the time info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b182b70c-26b2-49a9-996f-be8e10d8adf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_current_time_info():\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime('%H:%M')\n",
    "    current_day = now.strftime('%A')\n",
    "    return current_day, current_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6842c5b4-2749-4828-ba15-ad316234b30e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Speak Commads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76bf1532-2f1f-4ed6-be17-940c20103911",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3 in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (2.98)\n",
      "Requirement already satisfied: comtypes in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (from pyttsx3) (1.4.7)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (from pyttsx3) (305.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "393a3947-9a6f-48cc-a9db-957d24fef4b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "# import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcbdb799-50dd-468f-8a4e-00349a57009e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " def speak(text):\n",
    "        engine = pyttsx3.init()\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "\n",
    "# def thread_speak(text):\n",
    "#     speak_thread = threading.Thread(target=speak, args=(text,))\n",
    "#     speak_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4c47f9-51e3-4bd0-bfcb-fe6b53258b4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Speech Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8483ee59-2476-411d-b45a-bdf87c62afe5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (3.11.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (from SpeechRecognition) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (from SpeechRecognition) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a7d371f-83a9-4e8f-b0ec-b24a8f71915d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89f53aae-de21-40b9-8bf7-893270bb7da2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\users\\ibrah\\anaconda3\\lib\\site-packages (0.2.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef673ec5-361a-443c-92f4-506138a28710",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_user_response():\n",
    "    recognizer = sr.Recognizer()\n",
    "    \n",
    "    with sr.Microphone() as source:\n",
    "        print(\"I am listening your response\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "        \n",
    "    try:\n",
    "        response = recognizer.recognize_google(audio) ## convert the text\n",
    "        print(f'you said: {response}')\n",
    "        return response\n",
    "    except sr.UnknownValueError:\n",
    "        print('I could not understand the audio')\n",
    "        return \"\"\n",
    "    except sr.RequestError:\n",
    "        print(\"could not request from Google\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "116210de-c00f-4f4a-9e7a-e0c4fbfdb840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_key_weather = ''\n",
    "api_key_news = ''\n",
    "city = ''\n",
    "current_day, current_time = get_current_time_info()\n",
    "weather_info = get_weather_info(api_key_weather,city)\n",
    "\n",
    "headlines = get_news(api_key_news)\n",
    "\n",
    "def read_news(headlines):\n",
    "    for index, title in enumerate(headlines):\n",
    "        speak(f'News {index + 1}: {title}')\n",
    "        \n",
    "        \n",
    "def ask_for_agenda():\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        speak('Would you like me to write your agenda for today?')\n",
    "        response_agenda = get_user_response().strip()\n",
    "    \n",
    "        if response_agenda == \"\":\n",
    "            speak(\"I could't understand your response. Please try again\")\n",
    "            continue\n",
    "    \n",
    "        if 'yes' in response_agenda.lower():\n",
    "            speak('What would you like me to add to your agenda for today?')\n",
    "            agenda_entries = []\n",
    "        \n",
    "            while True:\n",
    "            \n",
    "                agenda_item = get_user_response().strip()\n",
    "                if agenda_item.lower() in ['okay', 'done', 'finish', 'thank you']:\n",
    "                    break\n",
    "                agenda_entries.append(agenda_item)\n",
    "            \n",
    "        \n",
    "            with open(\"daily_agenda.txt\", 'a') as f:\n",
    "                for item in agenda_entries:\n",
    "                    f.write(item + \"\\n\")\n",
    "   \n",
    "            speak(\"I have saved your agenda for today. Have a good day\")\n",
    "            break\n",
    "        \n",
    "        elif 'no' in response_agenda.lower():\n",
    "            speak('Okay, let me know if you need anything else.')\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            speak(\"I could not understand your response. Please answer with yes or no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a17c3-2c73-47da-8135-f4d1a913f69b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c32cf93-9abb-45cf-a32e-6d2c7291251e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet(\"yolov4.weights\", \"yolov4.cfg\") ## importing weights and configuration\n",
    "\n",
    "with open('coco.names', 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()] ## removing spaces and making al list for the objects\n",
    "                                                       ## coco.names provides names us\n",
    "\n",
    "def detect_coffee(frame):\n",
    "    height, width = frame.shape[:2] ## we only take the height and width of the entire image; the first two elements provide only the height and width\n",
    "    ## converting to blob format because yolo is using blob format.\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416,416), (0, 0, 0), True, crop=False) \n",
    "    net.setInput(blob) ## input for YOLO\n",
    "    \n",
    "    output_layers = net.getUnconnectedOutLayersNames() ##layers \n",
    "    outputs = net.forward(output_layers) ## The coordinates of the predicted objects, along with their respective classes and other details, are all included in the outputs.\n",
    "    \n",
    "    boxes = [] ## The coordinates of the detected objects\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    \n",
    "    coffee_detected = False\n",
    "    \n",
    "    \n",
    "    for output in outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]  # scores of the class\n",
    "            class_id = np.argmax(scores)  # find the class that has highest score\n",
    "            confidence = scores[class_id]  # get the score\n",
    "\n",
    "            \n",
    "            if confidence > 0.5:  \n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                # calculating the corner coordinates of the rectangle\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "                    \n",
    "    # apply Non-Maxima Suppression to prevent detecting the same object multiple times.\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    # show results\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            if label == 'cup':  # to detect cup\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)  # green rectangle\n",
    "                cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                coffee_detected = True\n",
    "                   \n",
    "    return coffee_detected      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf18e5f3-88ca-4616-8d7b-1da51870cb4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### detect_face function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf5581dc-17f6-4212-a87f-86d16456f59a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "greeted_user = False \n",
    "coffee_detected =  False\n",
    "news_read = False\n",
    "\n",
    "##news_read su ise yarar\n",
    "##eger cup tespit edildiyse ve kullanici cevap vermeden konum degistirdiyse else ile tekrardan soruyoruz, \n",
    "## ama cevap verdiyse tekrardan konum degistirdiginde ayni soru sorulmasini engellemek icin yazdim\n",
    "## news_read is useful for this.\n",
    "\n",
    "## If a cup is detected and the user changes location without responding, we ask again using else.\n",
    "## However, if they have responded, I've written this to prevent the same question from being asked again when the location changes.`\n",
    "\n",
    "\n",
    "def detect_face(frame):\n",
    "    global greeted_user,coffee_detected,news_read\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) ## tranform the picture to gray color. Because it is easier to detect with non-colour\n",
    "    faces = detector(gray_frame) ## searches for faces in the grayscale image and assigns the coordinates of the detected faces to the variable  \n",
    "    coffee_detected_now = detect_coffee(frame)\n",
    "    \n",
    "    for face in faces:\n",
    "        shape = predictor(gray_frame, face) ## gets the coordinates of the important landmarks of the face, such as the eyes, nose, etc\n",
    "        face_encoding = face_descriptor_extractor.compute_face_descriptor(frame, shape) ## Face encoding is a vector; here, there is a numerical value that identifies the face, which is typically an array of 128 values.\n",
    "            ## yani face_encoding yuzu tanimlayan ayir edici ozellklerdir\n",
    "            ## In other words, face_encoding consists of distinguishing features that identify the face.\n",
    "        distances = []\n",
    "        \n",
    "        \n",
    "        for known_faces_encoding in known_faces_encodings:\n",
    "            distance = np.linalg.norm(np.array(face_encoding) - np.array(known_faces_encoding))\n",
    "            ## daha once yukledigin resim ile tespit edilen yuz arasindaki mesafe yani o vektorler ne kadar azsa yuz o kadar benzerdir\n",
    "            ## The distance between the previously uploaded image and the detected face means that the smaller the vectors, the more similar the faces are.\n",
    "            distances.append(distance)\n",
    "            \n",
    "        min_distance_index = np.argmin(distances) ## bilinen yuzlerden hangisine en yakin oldugunu buldu yani mesafesi en az olanin indeksini aldi\n",
    "        ## It found which of the known faces is the closest, meaning it obtained the index of the one with the smallest distance.\n",
    "        if distances[min_distance_index] < 0.6:  # if the face is detected so if it is smmaller than 0.6\n",
    "            name = known_faces_names[min_distance_index] ## we obtained the names; note that the indices have the same order as the name\n",
    "            x1, y1, x2, y2 = (face.left(), face.top(), face.right(), face.bottom())\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "            \n",
    "            if not greeted_user: ## greeted user is false \n",
    "            \n",
    "                speak(f\"Good morning {name}, today is {current_day}, the time is {current_time} and {weather_info}\")\n",
    "                ask_for_agenda()\n",
    "                greeted_user = True\n",
    "             \n",
    "            if coffee_detected_now and not coffee_detected and not news_read:\n",
    "                speak(f\"I see your coffee is ready, would you like me to read today's news headlines?\")\n",
    "                respond_news = get_user_response().strip()\n",
    "                if \"yes\" in respond_news.lower():\n",
    "                    read_news(headlines)\n",
    "                    news_read = True\n",
    "                elif \"no\" in respond_news.lower():\n",
    "                    speak(f\"Okay have a good day {name}\")\n",
    "                    news_read = True\n",
    "                coffee_detected = True\n",
    "                \n",
    "            else:\n",
    "                ## if the user has not respond yet, ask again \n",
    "                coffee_detected = False\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe324e0-58fd-47fa-ba37-301edcee76a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Launching Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "456a4cb8-8e0f-40cd-bdff-622016becea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## open the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22b3cee8-5313-42db-893a-7ae39e5c04dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e35b0411-17ea-4527-b5c0-766b203f7ba6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am listening your response\n",
      "you said: no\n",
      "I am listening your response\n",
      "you said: no\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0) ## to open camera\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read() ## ret: did the camera read the frame correctly --> True or false\n",
    "                            ## frame: the captured image\n",
    "    if not ret:   ## if not captured image, it is false and close camera\n",
    "        break\n",
    "        \n",
    "    \n",
    "        \n",
    "    detect_face(frame) \n",
    "    detect_coffee(frame)\n",
    "    \n",
    "    cv2.imshow('Face and Cup Detection', frame) ## show me after processing\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): ## wait 1 ms every loop and exit with q\n",
    "        break\n",
    "\n",
    "cap.release() ## Close the camera; this means the camera can now be used by other applications\n",
    "cv2.destroyAllWindows() ## close all opencv windows\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c745e1-b31b-4f71-9244-42f7fae5f026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2637426a-c609-4ebb-a14e-7292aa8686a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
